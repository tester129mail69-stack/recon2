"""Subdomain aggregator module — merges results from all enumeration sources.

Automatically publishes discovered subdomains to the shared store so the
vulnerability module can scan every subdomain found.
"""

from __future__ import annotations

import asyncio
import importlib
import inspect
import pkgutil
import time
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

from godrecon.core.config import Config
from godrecon.modules.base import BaseModule, Finding, ModuleResult
from godrecon.modules.subdomains import register_subdomains
from godrecon.modules.subdomains.sources.base import SubdomainSource
from godrecon.utils.dns_resolver import AsyncDNSResolver
from godrecon.utils.helpers import deduplicate, is_valid_domain
from godrecon.utils.logger import get_logger

logger = get_logger(__name__)

_SOURCES_PKG = "godrecon.modules.subdomains.sources"


def _discover_source_classes() -> List[type]:
    import godrecon.modules.subdomains.sources as sources_pkg

    classes: List[type] = []
    sources_path = Path(sources_pkg.__file__).parent

    for module_info in pkgutil.iter_modules([str(sources_path)]):
        if module_info.name in ("__init__", "base"):
            continue
        try:
            mod = importlib.import_module(f"{_SOURCES_PKG}.{module_info.name}")
        except Exception as exc:
            logger.debug("Failed to import source module %s: %s", module_info.name, exc)
            continue
        for _name, obj in inspect.getmembers(mod, inspect.isclass):
            if (
                issubclass(obj, SubdomainSource)
                and obj is not SubdomainSource
                and obj.__module__ == mod.__name__
            ):
                classes.append(obj)
    return classes


def _build_sources(config: Config) -> List[SubdomainSource]:
    api = config.api_keys
    sources: List[SubdomainSource] = []

    _API_KEY_CONSTRUCTORS: Dict[str, Any] = {
        "virustotal": lambda: __import__(
            "godrecon.modules.subdomains.sources.virustotal", fromlist=["VirusTotalSource"]
        ).VirusTotalSource(api.virustotal),
        "securitytrails": lambda: __import__(
            "godrecon.modules.subdomains.sources.securitytrails",
            fromlist=["SecurityTrailsSource"],
        ).SecurityTrailsSource(api.securitytrails),
        "shodan": lambda: __import__(
            "godrecon.modules.subdomains.sources.shodan", fromlist=["ShodanSource"]
        ).ShodanSource(api.shodan),
        "censys_id": lambda: __import__(
            "godrecon.modules.subdomains.sources.censys", fromlist=["CensysSource"]
        ).CensysSource(api.censys_id, api.censys_secret),
        "binaryedge": lambda: __import__(
            "godrecon.modules.subdomains.sources.binaryedge", fromlist=["BinaryEdgeSource"]
        ).BinaryEdgeSource(api.binaryedge),
        "hunter": lambda: __import__(
            "godrecon.modules.subdomains.sources.hunter", fromlist=["HunterSource"]
        ).HunterSource(api.hunter),
        "fullhunt": lambda: __import__(
            "godrecon.modules.subdomains.sources.fullhunt", fromlist=["FullHuntSource"]
        ).FullHuntSource(api.fullhunt),
        "github": lambda: __import__(
            "godrecon.modules.subdomains.sources.github_search",
            fromlist=["GitHubSearchSource"],
        ).GitHubSearchSource(api.github),
    }

    source_classes = _discover_source_classes()
    for cls in source_classes:
        if not cls.requires_api_key:
            try:
                sources.append(cls())
            except Exception as exc:
                logger.debug("Failed to instantiate %s: %s", cls.__name__, exc)
        else:
            key_name = cls.api_key_name
            key_value = getattr(api, key_name, "") if hasattr(api, key_name) else ""
            if not key_value:
                logger.debug(
                    "Skipping %s — API key '%s' not configured", cls.name, key_name
                )
                continue
            constructor = _API_KEY_CONSTRUCTORS.get(key_name)
            if constructor:
                try:
                    sources.append(constructor())
                except Exception as exc:
                    logger.debug("Failed to instantiate %s: %s", cls.__name__, exc)

    return sources


class SubdomainAggregator(BaseModule):
    """Aggregate subdomains from 40+ passive sources, brute-force, and permutations.

    After discovery completes, all found subdomains are published to the
    shared store so VulnerabilityModule can automatically scan each one.
    """

    name        = "subdomains"
    description = "Subdomain enumeration and aggregation (40+ sources)"
    author      = "GODRECON Team"
    version     = "0.3.0"
    category    = "discovery"

    async def _execute(self, target: str, config: Config) -> ModuleResult:
        result  = ModuleResult(module_name=self.name, target=target)
        sub_cfg = config.subdomains
        timeout_per_source = sub_cfg.timeout_per_source

        # ── Phase 1: passive sources ────────────────────────────────────
        all_subdomains: Dict[str, List[str]] = {}
        source_stats:   Dict[str, int]       = {}

        sources = _build_sources(config)
        logger.info("Running %d subdomain sources for %s", len(sources), target)

        async def _run_source(src: SubdomainSource) -> Tuple[str, Set[str]]:
            t0    = time.monotonic()
            found = await src.fetch_safe(target, timeout=float(timeout_per_source))
            logger.info(
                "Source %-20s → %3d subdomains in %.1fs",
                src.name, len(found), time.monotonic() - t0,
            )
            return src.name, found

        gathered = await asyncio.gather(
            *[asyncio.create_task(_run_source(src)) for src in sources],
            return_exceptions=True,
        )

        for item in gathered:
            if isinstance(item, Exception):
                logger.debug("Source task exception: %s", item)
                continue
            src_name, found = item
            source_stats[src_name] = len(found)
            for sub in found:
                sub = sub.lower().strip().rstrip(".")
                if not is_valid_domain(sub):
                    continue
                if not (sub.endswith(f".{target}") or sub == target):
                    continue
                if sub not in all_subdomains:
                    all_subdomains[sub] = []
                if src_name not in all_subdomains[sub]:
                    all_subdomains[sub].append(src_name)

        # ── Phase 2: DNS brute-force ────────────────────────────────────
        if sub_cfg.bruteforce.enabled:
            logger.info("Starting DNS brute-force for %s", target)
            from godrecon.modules.subdomains.bruteforce import BruteForceModule
            try:
                async with BruteForceModule(
                    wordlist_path=sub_cfg.bruteforce.wordlist,
                    concurrency=sub_cfg.bruteforce.concurrency,
                    nameservers=config.dns.resolvers,
                    timeout=config.dns.timeout,
                ) as bf:
                    bf_results = await bf.run(target)
                source_stats["bruteforce"] = len(bf_results)
                for sub in bf_results:
                    sub = sub.lower()
                    if sub not in all_subdomains:
                        all_subdomains[sub] = ["bruteforce"]
                    elif "bruteforce" not in all_subdomains[sub]:
                        all_subdomains[sub].append("bruteforce")
                logger.info("Brute-force found %d subdomains for %s", len(bf_results), target)
            except Exception as exc:
                logger.warning("Brute-force error: %s", exc)

        # ── Phase 3: permutation scanning ──────────────────────────────
        if sub_cfg.permutation.enabled and all_subdomains:
            logger.info("Starting permutation scan for %s", target)
            from godrecon.modules.subdomains.permutation import PermutationScanner
            try:
                async with PermutationScanner(
                    nameservers=config.dns.resolvers,
                    timeout=config.dns.timeout,
                ) as scanner:
                    perm_results = await scanner.run(
                        domain=target,
                        known=set(all_subdomains.keys()),
                    )
                source_stats["permutation"] = len(perm_results)
                for sub in perm_results:
                    sub = sub.lower()
                    if sub not in all_subdomains:
                        all_subdomains[sub] = ["permutation"]
                    elif "permutation" not in all_subdomains[sub]:
                        all_subdomains[sub].append("permutation")
                logger.info(
                    "Permutation scanner found %d new subdomains for %s",
                    len(perm_results), target,
                )
            except Exception as exc:
                logger.warning("Permutation scanner error: %s", exc)

        # ── Phase 4: resolve all discovered subdomains ──────────────────
        discovered_list = list(all_subdomains.keys())
        resolved_ips: Dict[str, List[str]] = {}
        is_wildcard: bool = False

        if discovered_list:
            logger.info(
                "Resolving %d unique subdomains for %s", len(discovered_list), target
            )
            try:
                async with AsyncDNSResolver(
                    nameservers=config.dns.resolvers,
                    timeout=config.dns.timeout,
                    concurrency=200,
                ) as resolver:
                    is_wildcard = await resolver.detect_wildcard(target)
                    if is_wildcard:
                        logger.info(
                            "Wildcard DNS detected for %s — results may include false positives",
                            target,
                        )
                    resolved_ips = await resolver.bulk_resolve(discovered_list, "A")
            except Exception as exc:
                logger.warning("DNS resolution error: %s", exc)

        # ── Phase 5: recursive enumeration (optional) ───────────────────
        if sub_cfg.recursive.enabled:
            await self._recursive_enum(
                target=target,
                known=all_subdomains,
                resolved_ips=resolved_ips,
                config=config,
                depth=sub_cfg.recursive.depth,
            )

        # ── Phase 6: publish to shared store ────────────────────────────
        # Only publish subdomains that actually resolved — no point scanning
        # dead subdomains for vulns
        live_subdomains = [
            sub for sub in all_subdomains
            if resolved_ips.get(sub)
        ]
        # Always include the root target itself
        if target not in live_subdomains:
            live_subdomains.insert(0, target)

        register_subdomains(target, live_subdomains)
        logger.info(
            "Published %d live subdomains to shared store for vuln scanning",
            len(live_subdomains),
        )

        # ── Phase 7: build findings ──────────────────────────────────────
        for sub, srcs in all_subdomains.items():
            ips        = resolved_ips.get(sub, [])
            confidence = min(len(srcs), 3)
            result.findings.append(
                Finding(
                    title=f"Subdomain: {sub}",
                    description=(
                        f"Discovered via: {', '.join(srcs)}\n"
                        f"Resolves to: {', '.join(ips) if ips else 'unresolved'}"
                    ),
                    severity="info",
                    data={
                        "subdomain":    sub,
                        "ip_addresses": ips,
                        "sources":      srcs,
                        "confidence":   confidence,
                        "live":         bool(ips),
                    },
                    tags=["subdomain", "dns"],
                )
            )

        discovered = deduplicate(list(all_subdomains.keys()))
        result.raw = {
            "subdomains":        discovered,
            "live_subdomains":   live_subdomains,
            "count":             len(discovered),
            "live_count":        len(live_subdomains),
            "source_stats":      source_stats,
            "wildcard_detected": is_wildcard,
        }
        logger.info(
            "Subdomain aggregator complete for %s — %d total, %d live",
            target, len(discovered), len(live_subdomains),
        )
        return result

    async def _recursive_enum(
        self,
        target: str,
        known: Dict[str, List[str]],
        resolved_ips: Dict[str, List[str]],
        config: Config,
        depth: int,
    ) -> None:
        if depth <= 0:
            return

        interesting = [
            sub for sub, ips in resolved_ips.items()
            if ips and sub.count(".") == 1 + target.count(".")
        ]
        if not interesting:
            return

        logger.info(
            "Recursive enumeration: depth=%d, %d candidates for %s",
            depth, len(interesting), target,
        )

        _COMMON_SUBS = [
            "www", "mail", "api", "dev", "test", "staging", "admin", "portal",
            "app", "beta", "cdn", "static", "media", "internal", "vpn",
        ]

        try:
            async with AsyncDNSResolver(
                nameservers=config.dns.resolvers,
                timeout=config.dns.timeout,
                concurrency=100,
            ) as resolver:
                for sub_domain in interesting[:10]:
                    candidates = [f"{s}.{sub_domain}" for s in _COMMON_SUBS]
                    resolved   = await resolver.bulk_resolve(candidates, "A")
                    for full_sub, ips in resolved.items():
                        if ips and full_sub not in known:
                            known[full_sub]        = ["recursive"]
                            resolved_ips[full_sub] = ips
        except Exception as exc:
            logger.debug("Recursive enum error: %s", exc)
